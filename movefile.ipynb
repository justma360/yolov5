{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting CVAT to be added to Coco2017 dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First we need to convert the CVAT Yolo 1.1 style (class number) so it can be add it on top of coco dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'c:\\\\Users\\\\justm\\\\Documents\\\\OID_YoloV5\\\\yolov5\\\\datasets\\\\coco-additions\\\\finished\\\\train.txt'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "coco_additions_path = os.path.join(os.getcwd(),\"datasets/coco-additions/\")\n",
    "# Find all the new classes (folders in coco-additions)\n",
    "additional_classes = os.listdir(coco_additions_path)  \n",
    "\n",
    "# New objects\n",
    "for obj in additional_classes:\n",
    "  new_obj_path=os.path.normpath(os.path.join(coco_additions_path,obj))\n",
    "  try: \n",
    "    # Try to copy the original train.txt into a train_original.txt\n",
    "    train_txt_file=os.path.normpath(os.path.join(new_obj_path,\"train.txt\"))\n",
    "    shutil.copyfile(train_txt_file, os.path.normpath(os.path.join(new_obj_path,\"train_original.txt\")))\n",
    "  except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we change the class number of all the coco-additions (prompt user for input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justm\\Documents\\OID_YoloV5\\yolov5\\datasets/coco-additions/electric_hoverboard Does not have 'obj_train_data' folder in it, skipped\n",
      "c:\\Users\\justm\\Documents\\OID_YoloV5\\yolov5\\datasets/coco-additions/electric_scooter Does not have 'obj_train_data' folder in it, skipped\n",
      "c:\\Users\\justm\\Documents\\OID_YoloV5\\yolov5\\datasets/coco-additions/electric_unicycle Does not have 'obj_train_data' folder in it, skipped\n",
      "c:\\Users\\justm\\Documents\\OID_YoloV5\\yolov5\\datasets/coco-additions/finished Does not have 'obj_train_data' folder in it, skipped\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "coco_additions_path = os.path.join(os.getcwd(),\"datasets/coco-additions/\")\n",
    "additional_classes = os.listdir(coco_additions_path)\n",
    "\n",
    "\n",
    "for obj in additional_classes:\n",
    "  new_obj_path=os.path.join(coco_additions_path,obj)\n",
    "\n",
    "  try:\n",
    "    # Ask for a new class number for certain object\n",
    "    obj_train_data = os.path.join(new_obj_path,\"obj_train_data\") # get the specific file \n",
    "    additional_obj_train_data = [os.path.normpath(os.path.join(obj_train_data,file))  for file in os.listdir(obj_train_data) if  file.endswith(\".txt\")] # find txt in new object \n",
    "    class_number  = int(input(f\"[{obj}]Please enter a the new class number as an integer\"))\n",
    "\n",
    "    # For all text files (all the labels) replace the label number (row[0]) with new class_number \n",
    "    for text_file in additional_obj_train_data: \n",
    "      annotations = [] \n",
    "      with open(text_file) as f: \n",
    "          for line in f:\n",
    "            labels = line.split() \n",
    "            if (not labels[0].isdigit()): #  Issue where the label is not a digit (not a class number)\n",
    "              raise Exception(text_file, \"Label is not a digit (possibly still a label not a number)\") \n",
    "\n",
    "            labels[0] = class_number # Change the class number\n",
    "            newline = str(labels[0]) + \" \" + str(labels[1]) + \" \" + str(labels[2]) + \" \" + str(labels[3]) + \" \" + str(labels[4])\n",
    "            line = line.replace(line, newline)\n",
    "            annotations.append(line)\n",
    "          f.close()\n",
    "\n",
    "      # Write all the labels into that text file\n",
    "      with open(text_file, \"w\") as outfile:\n",
    "        for line in annotations:\n",
    "            outfile.write(line)\n",
    "            outfile.write(\"\\n\")\n",
    "        outfile.close()\n",
    "\n",
    "  except Exception as e: # case the folder doesn't have data (moved / edited)\n",
    "    print(new_obj_path, \"Does not have 'obj_train_data' folder in it, skipped\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changing format of text file that holds location of images \n",
    "\n",
    "Change the  `coco_additions/<object>/train.txt` file so that it matches the coco2017 dataset ```datasets/coco2017/train2017.txt``` style\n",
    "\n",
    "CVAT yolo style  = ```data/obj_train_data/hoverboard_0.jpg```\n",
    "\n",
    "CoCo train2017.txt style = ```./images/train2017/000000109622.jpg```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justm\\Documents\\OID_YoloV5\\yolov5\\datasets\\coco-additions\\finished Does not have 'train.txt' folder in it, skipped\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "coco_additions_path = os.path.join(os.getcwd(),\"datasets/coco-additions/\")\n",
    "additional_classes = os.listdir(coco_additions_path)\n",
    "\n",
    "# For all classes \n",
    "for obj in additional_classes:\n",
    "  new_obj_path=os.path.normpath(os.path.join(coco_additions_path,obj))\n",
    "\n",
    "  try:\n",
    "    # Copy the original to train.txt (so we don't get duplicates) \n",
    "    train_txt_file=os.path.normpath(os.path.join(new_obj_path,\"train.txt\"))\n",
    "    shutil.copyfile(os.path.normpath(os.path.join(new_obj_path,\"train_original.txt\")),train_txt_file)\n",
    "\n",
    "    # We change the CVAT stype to YOLO \n",
    "    annotations = []\n",
    "    with open(train_txt_file) as f: # open text file\n",
    "        for line in f: # for each line\n",
    "          image_name = line.split(\"/\")[-1].strip() # removes \\n at the end as well\n",
    "          image_line = f\"./images/train2017/{image_name}\"\n",
    "          annotations.append(image_line) # List of string for each line (replace first value with class number entered)\n",
    "        f.close()\n",
    "    with open(train_txt_file, \"w\") as outfile:\n",
    "      for line in annotations:\n",
    "          outfile.write(line)\n",
    "          outfile.write(\"\\n\")\n",
    "      outfile.close()\n",
    "  except Exception as e: \n",
    "    print(new_obj_path, \"Does not have 'train.txt' folder in it, skipped\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge the CVAT train.txt into the coco2017.txt\n",
    "\n",
    "BUGS: allows duplicates of the same, however yoloV5 training model should be able to deal with it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.8.10 ('venv': venv)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'c:/Users/justm/Documents/OID_YoloV5/venv/Scripts/python.exe -m pip install ipykernel -U --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "# copy train2017_original.txt to train2017.txt\n",
    "coco2017_train_path = os.path.join(os.getcwd(),\"datasets/coco2017/train2017.txt\") # opens the train.txt path\n",
    "shutil.copyfile(os.path.normpath(os.path.join(os.getcwd(),\"datasets/coco2017/train2017_original.txt\")),coco2017_train_path) # copy original to train \n",
    "\n",
    "\n",
    "coco2017_file_obj = open(coco2017_train_path, 'a') # open folder to append stuff\n",
    "\n",
    "coco_additions_path = os.path.join(os.getcwd(),\"datasets/coco-additions/\")\n",
    "additional_classes = os.listdir(coco_additions_path)\n",
    "for obj in additional_classes: # for all classes \n",
    "  new_obj_path=os.path.normpath(os.path.join(coco_additions_path,obj))\n",
    "\n",
    "  try: \n",
    "    # Each class we open the train.txt file\n",
    "    train_txt_file=os.path.normpath(os.path.join(new_obj_path,\"train.txt\"))\n",
    "    with open(train_txt_file) as f: # open text file\n",
    "          for line in f: # for each line\n",
    "            coco2017_file_obj.write(line) # Append the image path to the .txt file\n",
    "          f.close() # close file when done\n",
    "    print(new_obj_path, \"Has been appended to datasets/coco2017/train2017.txt\")\n",
    "  except:\n",
    "    print(new_obj_path, \"Does not have 'train.txt' folder in it, skipped\")\n",
    "coco2017_file_obj.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Move images to coco dataset\n",
    "\n",
    "Once everything is sure to correct \n",
    "\n",
    "Checklist \n",
    "1. The classes labels are all changed (no duplicate class number 80+)\n",
    "2. The path format of the CVAT images are changed to match the coco dataset (```./images/train2017/000000109622.jpg```)\n",
    "3. datasets/coco2017/train2017.txt has the new images appended to the bottom \n",
    "   \n",
    "Now we need to move the images and the labels into their corresponding folder in coco2017 dataset \n",
    "\n",
    "*WARNING*\n",
    "\n",
    "Once moved it will be almost impossible to move the files out as they will be mixed within the CoCo2017 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Moved] bicycle_helmet images and labels to coco paths c:\\Users\\justm\\Documents\\OID_YoloV5\\yolov5\\datasets\\coco2017\\images\\train2017\n",
      "[Moved] electric_hoverboard images and labels to coco paths c:\\Users\\justm\\Documents\\OID_YoloV5\\yolov5\\datasets\\coco2017\\images\\train2017\n",
      "[Moved] electric_scooter images and labels to coco paths c:\\Users\\justm\\Documents\\OID_YoloV5\\yolov5\\datasets\\coco2017\\images\\train2017\n",
      "[Moved] electric_unicycle images and labels to coco paths c:\\Users\\justm\\Documents\\OID_YoloV5\\yolov5\\datasets\\coco2017\\images\\train2017\n",
      "c:\\Users\\justm\\Documents\\OID_YoloV5\\yolov5\\datasets/coco-additions/finished Does not have 'obj_train_data' folder in it, skipped\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "coco_additions_path = os.path.join(os.getcwd(),\"datasets/coco-additions/\")\n",
    "additional_classes = os.listdir(coco_additions_path)\n",
    "\n",
    "# all classes\n",
    "for obj in additional_classes:\n",
    "  new_obj_path=os.path.join(coco_additions_path,obj)\n",
    "  try:\n",
    "    obj_train_data = os.path.join(new_obj_path,\"obj_train_data\") # get the specific file \n",
    "    jpg_names = [os.path.splitext(file)[0]  for file in os.listdir(obj_train_data) if  file.endswith(\".jpg\")] # holds all the file names (no extensions)\n",
    "    coco_image_path = os.path.normpath(os.path.join(os.getcwd(),\"datasets/coco2017/images/train2017\"))\n",
    "    coco_label_path = os.path.normpath(os.path.join(os.getcwd(),\"datasets/coco2017/labels/train2017\"))\n",
    "    # C:\\Users\\justm\\Documents\\OID_YoloV5\\yolov5\\datasets\\coco2017\\images\\train2017\n",
    "    # C:\\Users\\justm\\Documents\\OID_YoloV5\\yolov5\\datasets\\coco2017\\labels\\train2017\n",
    "    \n",
    "    for image in jpg_names:\n",
    "      # Now we have the file name we add the extensions\n",
    "      label_file_name = image + \".jpg\"\n",
    "      jpg_file_name = image + \".txt\"\n",
    "      \n",
    "      # move from \"\\datasets\\coco-addition\\object\\obj_train_data\" to \"\\datasets\\coco2017\\labels\\train2017\"\n",
    "      shutil.move(os.path.normpath(os.path.join(obj_train_data,label_file_name)),os.path.normpath(os.path.join(coco_image_path,label_file_name)))\n",
    "      shutil.move(os.path.normpath(os.path.join(obj_train_data,jpg_file_name)),os.path.normpath(os.path.join(coco_label_path,jpg_file_name)))\n",
    "\n",
    "    print(f\"[Moved] {obj} images and labels to coco paths {coco_image_path}\")\n",
    "  except Exception as e: \n",
    "    print(new_obj_path, \"Does not have 'obj_train_data' folder in it, skipped\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting a custom amount of training samples\n",
    "\n",
    "Limit CoCo2017 dataset to a certain amount "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justm\\Documents\\OID_YoloV5\\yolov5\\datasets/coco2017/train2017.txt\n",
      "c:\\Users\\justm\\Documents\\OID_YoloV5\\yolov5\\datasets/coco-additions/finished Has been appended to train1000000.txt\n"
     ]
    }
   ],
   "source": [
    "limit = 10000 # Only keep this many photos\n",
    "\n",
    "coco_train_txt = os.path.join(os.getcwd(),\"datasets/coco2017/train2017.txt\")\n",
    "\n",
    "\n",
    "keep_lines = []\n",
    "with open(coco_train_txt) as f: # open text file\n",
    "    for line in f: # for each line\n",
    "      file_name = os.path.splitext(os.path.basename(line))[0]\n",
    "      if file_name.isdigit(): # is a digit number means its from coco \n",
    "        if len(keep_lines) < limit:\n",
    "          keep_lines.append(file_name)\n",
    "      else:\n",
    "        keep_lines.append(file_name)\n",
    "\n",
    "\n",
    "with open(os.path.join(os.getcwd(),\"datasets/coco2017/\" + f\"train{limit}.txt\"), 'w') as outfile:\n",
    "  for file_name in keep_lines:\n",
    "      line_value = f\"./images/train2017/{file_name}.jpg\"\n",
    "      outfile.write(line_value)\n",
    "      outfile.write(\"\\n\")\n",
    "outfile.close()\n",
    "\n",
    "\n",
    "print(new_obj_path, f\"Has been appended to train{limit}.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting OIDV4 downloaded to CVAT format\n",
    "\n",
    "OIDv4 is great because you can download already labelled images from the OpenImage dataset\n",
    "\n",
    "1. Check that the labels are in *class numbers* rather than *class names*\n",
    "2. Use \"yolov5_convert_annotations.py\" to convert to class number\n",
    "\n",
    "### This function below moves the converted OIDv4 Data into a format for COCO to be used in\n",
    "object_name = name of the folder that will be moved\n",
    "it will be converted to lower case with spaces replaced to underscores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justm\\Documents\\OID_YoloV5\\OIDv4_ToolKit\\OID\\Dataset\\train\\truck\\Label_yolo\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import shutil\n",
    "import time\n",
    "\n",
    "object_name = \"truck\"\n",
    "new_object_name = object_name.lower().replace(\" \",\"_\")\n",
    "\n",
    "oidv_obj = os.path.join( os.path.dirname(os.getcwd()),\"OIDv4_ToolKit\",\"OID\",\"Dataset\",\"train\",object_name)\n",
    "if os.path.exists(oidv_obj):\n",
    "  coco_addition_folder=os.path.join(os.getcwd(),\"datasets\",\"coco-additions\",new_object_name)\n",
    "  if not os.path.exists(coco_addition_folder):\n",
    "    os.makedirs(coco_addition_folder)\n",
    "    os.makedirs(os.path.join(coco_addition_folder,\"obj_train_data\"))\n",
    "    obj_train_data_path = os.path.join(coco_addition_folder,\"obj_train_data\")\n",
    "  # else: \n",
    "  #   raise Exception(f\"Object already exists in {coco_addition_folder}\")\n",
    "    \n",
    "  train_files = os.listdir(oidv_obj)\n",
    "  for file_names in [file for file in train_files if file.endswith(\".jpg\")]: # for files that are jpg\n",
    "    # print(os.path.join(oidv_obj,file_names))\n",
    "    source = os.path.normpath(os.path.join(oidv_obj,file_names))\n",
    "    dest = os.path.normpath(os.path.join(obj_train_data_path,file_names))\n",
    "    shutil.move(source,dest)\n",
    "\n",
    "  label_files_path = os.path.join(oidv_obj,\"Label_yolo\")\n",
    "  label_files = os.listdir(label_files_path)\n",
    "  for file_names in [file for file in label_files if file.endswith(\".txt\")]: # for files that are txt\n",
    "    source = os.path.normpath(os.path.join(label_files_path,file_names))\n",
    "    dest = os.path.normpath(os.path.join(obj_train_data_path,file_names))\n",
    "    shutil.move(source,dest)\n",
    "\n",
    "with open(os.path.join(coco_addition_folder,'obj.names'), 'w') as f:\n",
    "    f.write(new_object_name)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Afterwards you need need to generated a new train.txt and train.txt original \n",
    "\n",
    "These txt files are needed if you want to combine them with the coco dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justm\\Documents\\OID_YoloV5\\yolov5\\datasets\\airport\\motorcycle\\train_original.txt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\justm\\\\Documents\\\\OID_YoloV5\\\\yolov5\\\\datasets\\\\airport\\\\motorcycle\\\\train.txt'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "dataset_name=input(\"Please enter your dataset name\")\n",
    "train_text_format = f\"./data/{object_name}/images\"\n",
    "\n",
    "# what is the object name (as the image / label will be renamed to this)\n",
    "object_name = \"motorcycle\"\n",
    "obj_train_path = os.path.join(os.getcwd(),\"datasets\",dataset_name, object_name , \"obj_train_data\")\n",
    "\n",
    "###  Rename file\n",
    "train_files = os.listdir(obj_train_path)\n",
    "annotations= []\n",
    "for file_names in [file for file in train_files if file.endswith(\".jpg\")]: # for each line\n",
    "  image_line = f\"data/obj_train_data/{file_names}\"\n",
    "  annotations.append(image_line) # List of string for each line (replace first value with class number entered)\n",
    "\n",
    "# for all images rename to <class_name>_number\n",
    "for idx,files_names in enumerate(annotations):\n",
    "  # obj_train_path # folder path\n",
    "  txt_name = os.path.splitext(os.path.basename(files_names))[0]  + \".txt\"\n",
    "  jpg_name = os.path.basename(files_names)\n",
    "  try: \n",
    "    os.rename(obj_train_path + f\"/{txt_name}\", obj_train_path + f\"/{object_name}_{idx+1}\" + \".txt\" )\n",
    "    os.rename(obj_train_path + f\"/{jpg_name}\", obj_train_path + f\"/{object_name}_{idx+1}\" + \".jpg\") \n",
    "  except Exception as e:\n",
    "    pass\n",
    "    # print(f'File {txt_name} missing')\n",
    "time.sleep(3)\n",
    "\n",
    "### Read the files inside again after rename then write to train.txt\n",
    "train_files = os.listdir(obj_train_path)\n",
    "annotations= []\n",
    "for file_names in [file for file in train_files if file.endswith(\".jpg\")]: # for each line\n",
    "  image_line = f\"{train_text_format}/{file_names}\"\n",
    "  annotations.append(image_line) # List of string for each line (replace first value with class number entered)\n",
    "\n",
    "train_original_Path = os.path.join(os.getcwd(),\"datasets\",dataset_name, object_name , \"train_original.txt\")\n",
    "print(train_original_Path)\n",
    "with open(train_original_Path, 'w') as outfile:\n",
    "  for line in annotations:\n",
    "      outfile.write(line)\n",
    "      outfile.write(\"\\n\")\n",
    "outfile.close()\n",
    "shutil.copy(os.path.join(os.getcwd(),train_original_Path), os.path.join(os.getcwd(),\"datasets\",dataset_name, object_name , \"train.txt\"))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Separate training \n",
    "import os\n",
    "import shutil\n",
    "\n",
    "source_folder = obj_train_path\n",
    "destination_folder_images = os.path.abspath(os.path.join(obj_train_path, os.pardir,\"images\"))\n",
    "destination_folder_txt = os.path.abspath(os.path.join(obj_train_path, os.pardir,\"labels\"))\n",
    "\n",
    "if not os.path.exists(destination_folder_images):\n",
    "  os.mkdir(destination_folder_images)\n",
    "if not os.path.exists(destination_folder_txt):\n",
    "  os.mkdir(destination_folder_txt)\n",
    "\n",
    "# fetch all files\n",
    "for file_name in os.listdir(source_folder):\n",
    "    source = os.path.join(source_folder, file_name)\n",
    "    if  os.path.isfile(source):\n",
    "      if file_name.endswith(\".jpg\"):\n",
    "          destination = os.path.join(destination_folder_images,file_name)\n",
    "          shutil.move(source, destination)\n",
    "      elif file_name.endswith(\".txt\"):\n",
    "          destination = os.path.join(destination_folder_txt,file_name)\n",
    "          shutil.move(source, destination)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other functions that may be of use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete all images that dont start with 0000 \n",
    "Thus not part of original coco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C:\\Users\\justm\\Documents\\OID_YoloV5\\yolov5\\datasets\\coco2017\\images\\train2017\n",
    "\n",
    "images_path = r\"C:\\Users\\justm\\Documents\\OID_YoloV5\\yolov5\\datasets\\coco2017\\images\\train2017\"\n",
    "label_path = r\"C:\\Users\\justm\\Documents\\OID_YoloV5\\yolov5\\datasets\\coco2017\\labels\\train2017\"\n",
    "\n",
    "\n",
    "images_files = os.listdir(images_path)\n",
    "\n",
    "for names in images_files: \n",
    "  if names[0:4] != \"0000\": # original coco images are 0000\n",
    "    jpg_path = os.path.join(images_path,names)\n",
    "    label_names = names.split(\".\")[0] + \".txt\"\n",
    "    txt_path = os.path.join(label_path,label_names)\n",
    "    os.remove(jpg_path)\n",
    "    os.remove(txt_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Jacks Yolo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "any(p in \"my_text\" for p in punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\justm\\Documents\\OID_YoloV5\\yolov5\\datasets\\jack_dataset\\coco_skateboard_bicycle\\images\\train\n",
      "C:\\Users\\justm\\Documents\\OID_YoloV5\\yolov5\\datasets\\jack_dataset\\coco_skateboard_bicycle\\train.txt\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "import shutil\n",
    "jack_image_path = os.path.normpath(r\"C:\\Users\\justm\\Documents\\OID_YoloV5\\yolov5\\datasets\\jack_dataset\\coco_skateboard_bicycle\\images\\train\")\n",
    "jack_label_path = os.path.normpath(r\"C:\\Users\\justm\\Documents\\OID_YoloV5\\yolov5\\datasets\\jack_dataset\\coco_skateboard_bicycle\\labels\\train\")\n",
    "\n",
    "numbers = [str(i) for i in range(0,10)]\n",
    "\n",
    "print(jack_image_path)\n",
    "train_files = os.listdir(jack_image_path)\n",
    "# print(train_files)\n",
    "\n",
    "annotations= []\n",
    "for file_names in [file for file in train_files if file.endswith(\".jpg\")]: # for each line\n",
    "  f_name=os.path.splitext(file_names)[0]\n",
    "  if not any(p in f_name for p in punctuation):\n",
    "    image_line = f\"./images/train2017/{file_names}\"\n",
    "    annotations.append(image_line) # List of string for each line (replace first value with class number entered)\n",
    "\n",
    "\n",
    "\n",
    "print(os.path.normpath(r\"C:\\Users\\justm\\Documents\\OID_YoloV5\\yolov5\\datasets\\jack_dataset\\coco_skateboard_bicycle\\train.txt\"))\n",
    "with open(os.path.normpath(r\"C:\\Users\\justm\\Documents\\OID_YoloV5\\yolov5\\datasets\\jack_dataset\\coco_skateboard_bicycle\\train.txt\"), 'w') as outfile:\n",
    "  for line in annotations:\n",
    "      outfile.write(line)\n",
    "      outfile.write(\"\\n\")\n",
    "outfile.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\justm\\Documents\\OID_YoloV5\\yolov5\\datasets\\jack_dataset\\coco_skateboard_bicycle\\labels\\train\n"
     ]
    }
   ],
   "source": [
    "# Adjust head label to be 84\n",
    "obj = 'head'\n",
    "current_class_number = 85\n",
    "new_class_number = 84\n",
    "jack_label_path = os.path.normpath(r\"C:\\Users\\justm\\Documents\\OID_YoloV5\\yolov5\\datasets\\jack_dataset\\coco_skateboard_bicycle\\labels\\train\")\n",
    "print(jack_label_path)\n",
    "\n",
    "for file_name in os.listdir(jack_label_path): # for each line\n",
    "  text_file = os.path.join(jack_label_path,file_name)\n",
    "  annotations = []\n",
    "  with open(text_file) as f: # open text file\n",
    "      for line in f: # for each line\n",
    "        labels = line.split() \n",
    "        if (not labels[0].isdigit()):\n",
    "          raise Exception(text_file, \"label is not a digit (possible still a label not a number)\") \n",
    "        if (int(labels[0])) == current_class_number:\n",
    "          labels[0] = new_class_number\n",
    "          newline = str(labels[0]) + \" \" + str(labels[1]) + \" \" + str(labels[2]) + \" \" + str(labels[3]) + \" \" + str(labels[4])\n",
    "          line = line.replace(line, newline)\n",
    "          annotations.append(line) # List of string for each line (replace first value with class number entered)\n",
    "        else: \n",
    "          annotations.append(line) # List of string for each line (replace first value with class number entered)\n",
    "      f.close()\n",
    "\n",
    "  with open(text_file, \"w\") as outfile:\n",
    "    for line in annotations:\n",
    "        outfile.write(line)\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OID\\Dataset\\validation\\Vehicle_registration_plate\n"
     ]
    }
   ],
   "source": [
    "dataset=\"validation\"\n",
    "object_name = \"Vehicle_registration_plate\"\n",
    "object_folder = object_name.lower().replace(\" \", \"_\")  # new folder name\n",
    "\n",
    "# Get the images in the object folder\n",
    "oidv_obj_path = os.path.join( \"OID\", \"Dataset\", dataset, object_name)\n",
    "print(oidv_obj_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\justm\\Documents\\OID_YoloV5\\yolov5\\datasets\\airport\\motorcycle\\train\\labels\n",
      "C:\\Users\\justm\\Documents\\OID_YoloV5\\yolov5\\datasets\\airport\\motorcycle\\train\\labels\\motorcycle_1.txt\n",
      "['1 0.0630864375 0.48562341690962096 0.12421800000000001 0.284714', '1 0.7498044375 0.5265637551020408 0.49843799999999994 0.9416569999999999']\n"
     ]
    }
   ],
   "source": [
    "adjust_label_folder= r\"C:\\Users\\justm\\Documents\\OID_YoloV5\\yolov5\\datasets\\airport\\motorcycle\\train\\labels\"\n",
    "print(adjust_label_folder)\n",
    "\n",
    "\n",
    "file_names =  [\n",
    "        os.path.join(adjust_label_folder,file) for file in os.listdir(adjust_label_folder) if file.endswith(\".txt\")\n",
    "    ]\n",
    "\n",
    "print(file_names[0])\n",
    "\n",
    "def adjust_label(class_number: int, text_file: str) -> None:\n",
    "    annotations = []\n",
    "    with open(text_file) as f:\n",
    "        for line in f:\n",
    "            labels = line.split()\n",
    "            labels[0] = class_number  # Change the class number\n",
    "            newline = (\n",
    "                str(labels[0])\n",
    "                + \" \"\n",
    "                + str(labels[1])\n",
    "                + \" \"\n",
    "                + str(labels[2])\n",
    "                + \" \"\n",
    "                + str(labels[3])\n",
    "                + \" \"\n",
    "                + str(labels[4])\n",
    "            )\n",
    "            line = line.replace(line, newline)\n",
    "            annotations.append(line)\n",
    "    print(annotations)\n",
    "    with open(r\"C:\\Users\\justm\\OneDrive\\Desktop\\leave.txt\", \"w\") as outfile:\n",
    "        for line in annotations:\n",
    "            outfile.write(line)\n",
    "            outfile.write(\"\\n\")\n",
    "    outfile.close()\n",
    "\n",
    "adjust_label(1,file_names[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "44265fd2b9bb58bad603853871b28b1fc4b4939483226e9584da277546b03963"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
